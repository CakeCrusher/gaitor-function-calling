{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting git+https://github.com/huggingface/peft.git\n",
      "  Cloning https://github.com/huggingface/peft.git to /scratch/local/14526190/pip-req-build-or8lfpzs\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /scratch/local/14526190/pip-req-build-or8lfpzs\n",
      "  Resolved https://github.com/huggingface/peft.git to commit cfe35a7878b44e017836f0b0c0c3b3e9e0cb738b\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /apps/pytorch/2.0.1/lib/python3.10/site-packages (from peft==0.7.0.dev0) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /apps/pytorch/2.0.1/lib/python3.10/site-packages (from peft==0.7.0.dev0) (23.1)\n",
      "Requirement already satisfied: psutil in /apps/pytorch/2.0.1/lib/python3.10/site-packages (from peft==0.7.0.dev0) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /home/sosa.s/.local/lib/python3.10/site-packages (from peft==0.7.0.dev0) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /apps/pytorch/2.0.1/lib/python3.10/site-packages (from peft==0.7.0.dev0) (2.0.1)\n",
      "Requirement already satisfied: transformers in /home/sosa.s/.local/lib/python3.10/site-packages (from peft==0.7.0.dev0) (4.36.0.dev0)\n",
      "Requirement already satisfied: tqdm in /apps/pytorch/2.0.1/lib/python3.10/site-packages (from peft==0.7.0.dev0) (4.65.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /home/sosa.s/.local/lib/python3.10/site-packages (from peft==0.7.0.dev0) (0.24.1)\n",
      "Requirement already satisfied: safetensors in /home/sosa.s/.local/lib/python3.10/site-packages (from peft==0.7.0.dev0) (0.3.3)\n",
      "Requirement already satisfied: huggingface-hub in /home/sosa.s/.local/lib/python3.10/site-packages (from accelerate>=0.21.0->peft==0.7.0.dev0) (0.17.3)\n",
      "Requirement already satisfied: filelock in /home/sosa.s/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.7.0.dev0) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /home/sosa.s/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.7.0.dev0) (4.8.0)\n",
      "Requirement already satisfied: sympy in /apps/pytorch/2.0.1/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.7.0.dev0) (1.12)\n",
      "Requirement already satisfied: networkx in /apps/pytorch/2.0.1/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.7.0.dev0) (3.1)\n",
      "Requirement already satisfied: jinja2 in /apps/pytorch/2.0.1/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.7.0.dev0) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/sosa.s/.local/lib/python3.10/site-packages (from transformers->peft==0.7.0.dev0) (2023.8.8)\n",
      "Requirement already satisfied: requests in /apps/pytorch/2.0.1/lib/python3.10/site-packages (from transformers->peft==0.7.0.dev0) (2.29.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/sosa.s/.local/lib/python3.10/site-packages (from transformers->peft==0.7.0.dev0) (0.14.1)\n",
      "Requirement already satisfied: fsspec in /home/sosa.s/.local/lib/python3.10/site-packages (from huggingface-hub->accelerate>=0.21.0->peft==0.7.0.dev0) (2023.9.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /apps/pytorch/2.0.1/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.7.0.dev0) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /apps/pytorch/2.0.1/lib/python3.10/site-packages (from requests->transformers->peft==0.7.0.dev0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /apps/pytorch/2.0.1/lib/python3.10/site-packages (from requests->transformers->peft==0.7.0.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /apps/pytorch/2.0.1/lib/python3.10/site-packages (from requests->transformers->peft==0.7.0.dev0) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /apps/pytorch/2.0.1/lib/python3.10/site-packages (from requests->transformers->peft==0.7.0.dev0) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /apps/pytorch/2.0.1/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.7.0.dev0) (1.3.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting git+https://github.com/huggingface/transformers.git\n",
      "  Cloning https://github.com/huggingface/transformers.git to /scratch/local/14526190/pip-req-build-4vcoolev\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /scratch/local/14526190/pip-req-build-4vcoolev\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit cc3e4781854a52cf090ffde28d884a527dab6708\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/sosa.s/.local/lib/python3.10/site-packages (from transformers==4.36.0.dev0) (3.12.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/sosa.s/.local/lib/python3.10/site-packages (from transformers==4.36.0.dev0) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /apps/pytorch/2.0.1/lib/python3.10/site-packages (from transformers==4.36.0.dev0) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /apps/pytorch/2.0.1/lib/python3.10/site-packages (from transformers==4.36.0.dev0) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/sosa.s/.local/lib/python3.10/site-packages (from transformers==4.36.0.dev0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/sosa.s/.local/lib/python3.10/site-packages (from transformers==4.36.0.dev0) (2023.8.8)\n",
      "Requirement already satisfied: requests in /apps/pytorch/2.0.1/lib/python3.10/site-packages (from transformers==4.36.0.dev0) (2.29.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/sosa.s/.local/lib/python3.10/site-packages (from transformers==4.36.0.dev0) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/sosa.s/.local/lib/python3.10/site-packages (from transformers==4.36.0.dev0) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /apps/pytorch/2.0.1/lib/python3.10/site-packages (from transformers==4.36.0.dev0) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /home/sosa.s/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.36.0.dev0) (2023.9.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/sosa.s/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.36.0.dev0) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /apps/pytorch/2.0.1/lib/python3.10/site-packages (from requests->transformers==4.36.0.dev0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /apps/pytorch/2.0.1/lib/python3.10/site-packages (from requests->transformers==4.36.0.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /apps/pytorch/2.0.1/lib/python3.10/site-packages (from requests->transformers==4.36.0.dev0) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /apps/pytorch/2.0.1/lib/python3.10/site-packages (from requests->transformers==4.36.0.dev0) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q huggingface_hub\n",
    "!pip install -q -U trl transformers accelerate peft\n",
    "!pip install -q -U datasets bitsandbytes einops wandb\n",
    "!pip install git+https://github.com/huggingface/peft.git\n",
    "!pip install git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e8e5256a28d4a5a82b6ec40e89f1818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer, TrainingArguments\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_path_to_data = '../data/train.json'\n",
    "\n",
    "dataset = load_dataset('json', data_files={'train': relative_path_to_data}, split=\"train\")\n",
    "base_model_name = \"meta-llama/Llama-2-7b-hf\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa.s/.local/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:472: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7bd311e63754ae0a8fda05e0ee980fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/609 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b3278588b9c4ed7970fbfec5e778591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)fetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70879a253bf5483fa82db0749c48dd25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97f9d1b9f97408b89f0472c9f76826a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cffe7e1ace18442db5e037024ac098d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46658a29af06491b8c2a1ed3e8f21428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sosa.s/.local/lib/python3.10/site-packages/transformers/utils/hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69bcc3b953ed42cf8aede741c0ab1316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device_map = {\"\": 0}\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=device_map,\n",
    "    trust_remote_code=True,\n",
    "    use_auth_token=True\n",
    ")\n",
    "base_model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.config.pretraining_tp = 1 \n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ea8fbbdfe434d5b852a51ef99e97c15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "358f854c37fa4cc2ab985bb2630e4277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f640a3a61ca41ac94490fa9a7f4a312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f1a98ffe0624495a7452efc123ad008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77ebbb3d862045ad800fa0a54c3150f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"./results\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=2e-4,\n",
    "    logging_steps=10,\n",
    "    max_steps=500\n",
    ")\n",
    "\n",
    "max_seq_length = 512\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=base_model,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env NCCL_DEBUG=INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "\n",
    "import os\n",
    "output_dir = os.path.join(output_dir, \"final_checkpoint\")\n",
    "trainer.model.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import AutoPeftModelForCausalLM\n",
    "\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(output_dir, device_map=device_map, torch_dtype=torch.bfloat16)\n",
    "text = \"...\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), attention_mask=inputs[\"attention_mask\"], max_new_tokens=50, pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-2.0.1",
   "language": "python",
   "name": "pytorch-2.0.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
